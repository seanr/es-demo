<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE xml>
<!--
   Copyright 2010-2017 Norconex Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->

<!-- This self-documented configuration file is meant to be used as a reference
     or starting point for a new configuration.
     It contains all core features offered in this release.  Sometimes
     multiple implementations are available for a given feature. Refer
     to site documentation for more options and complete description of
     each features.
     -->
<httpcollector id="ES-Demo Collector">
  <!-- Location where internal progress files are stored. -->
  <progressDir>${workdir}/progress</progressDir>

  <!-- Location where logs are stored. -->
  <logsDir>${logsdir}</logsDir>

  #parse("../collector.xml")

  <!-- Individual crawlers can be defined here.  All crawler default
       configuration settings will apply to all crawlers created unless
       explicitly overwritten in crawler configuration.
       For configuration options where multiple items can be present
       (e.g. filters), the whole list will in crawler defaults would be
       overwritten.
       Since the options are the same as the defaults above, the documentation
       is not repeated here.
       The only difference from "crawlerDefaults" is the addition of the "id"
       attribute on the crawler tag.  The "id" attribute uniquely identifies
       each of your crawlers.
       -->
  <crawlers>
    <crawler id="$crawler-id">
      <startURLs stayOnDomain="true" stayOnPort="true" stayOnProtocol="true">
        <url>${crawler-url}</url>
        <sitemap>${crawler-url}sitemap.xml</sitemap>
      </startURLs>

      <!-- Add default importer -->
      #parse("../importer.xml")

      <!-- Add default committer -->
      #parse("../committer.xml")
    </crawler>
  </crawlers>
</httpcollector>
